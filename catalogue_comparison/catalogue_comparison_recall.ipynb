{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "sys.path.append('..')\n",
    "from resnet import resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(data, val_size=0.15, test_size=0.15, random_state=9):\n",
    "    assert val_size + test_size < 1\n",
    "    val_test_size = val_size + test_size\n",
    "    test_relative_size = test_size / val_test_size\n",
    "    \n",
    "    indices = range(data.shape[0])\n",
    "    train_indices, test_indices = train_test_split(indices, test_size=val_test_size, random_state=random_state)\n",
    "    val_indices, test_indices = train_test_split(test_indices, test_size=test_relative_size,\n",
    "                                                 random_state=random_state)\n",
    "    \n",
    "    return data[train_indices], data[val_indices], data[test_indices]\n",
    "\n",
    "def crop_center_or_pad(img, new_side):\n",
    "    _, y, x = img.shape\n",
    "    if x > new_side:\n",
    "        startx = x//2-(new_side//2)\n",
    "        return img[:, startx:startx+new_side,startx:startx+new_side]\n",
    "    elif x < new_side:\n",
    "        padx = (new_side//2) - x//2\n",
    "        return np.pad(img, ((0,), (padx,), (padx,)), mode='constant', constant_values=-1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root='../rebuild_dataset'\n",
    "sz_names = np.load(f'{root}/sz_oleg.npz')['sz_names']\n",
    "_, _, oleg_test = train_val_test_split(sz_names)\n",
    "oleg_all = [f'PSZ2 G{name}' for name in sz_names]\n",
    "oleg_test = [f'PSZ2 G{name}' for name in oleg_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Planck(Dataset):\n",
    "    def __init__(self, sz, split='None'):\n",
    "        _, _, sz_test = train_val_test_split(sz)\n",
    "        self.X = sz_test\n",
    "        self.y = np.array([1] * sz_test.shape[0], dtype=np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X, y = self.X[idx], self.y[idx]\n",
    "\n",
    "        X = X[:, ::2, ::2]\n",
    "        X = crop_center_or_pad(X, 128)\n",
    "        return torch.from_numpy(X), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sz.shape (1000, 5, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "root='../rebuild_dataset'\n",
    "sz = np.load(f'{root}/sz_oleg.npz')['sz_data'].astype(np.float32)\n",
    "print('sz.shape', sz.shape)\n",
    "\n",
    "test_dataset = Planck(sz, split='test')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = '../checkpoints/v2_128_oleg_14/net_best.pt'\n",
    "threshold = 0.4\n",
    "device = torch.device('cpu')\n",
    "\n",
    "model = resnet18(num_classes=1).to(device)\n",
    "model.load_state_dict(torch.load(checkpoint_name, map_location=device))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ours_pred = []\n",
    "for (X, y_true), name in zip(test_dataloader, oleg_test):\n",
    "    X, y_true = X.to(device), y_true.unsqueeze(1).float().to(device)\n",
    "    y_pred = torch.sigmoid(model(X))\n",
    "\n",
    "    if y_pred.item() > threshold:\n",
    "        ours_pred.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ours_pred = set(ours_pred)\n",
    "len(ours_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now find intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./mmf1.tsv') as f:\n",
    "    mmf1 = set([line[:-1] for line in f])\n",
    "with open('./mmf3.tsv') as f:\n",
    "    mmf3 = set([line[:-1] for line in f])\n",
    "with open('./pws.tsv') as f:\n",
    "    pws = set([line[:-1] for line in f])\n",
    "with open('./all.tsv') as f:\n",
    "    all = set([line[:-1] for line in f])\n",
    "# with open('./catalogue_comparison/ours.tsv') as f:\n",
    "#     ours_test = set([line[:-1] for line in f])\n",
    "# with open('./catalogue_comparison/ours_test.tsv') as f:\n",
    "#     ours_test = set([line[:-1] for line in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmf1: 0.75\n",
      "mmf3: 0.77\n",
      "pws: 0.64\n",
      "all: 1.00\n",
      "ours: 0.12\n"
     ]
    }
   ],
   "source": [
    "mmf1_score = len(mmf1.intersection(oleg_all)) / len(oleg_all)\n",
    "mmf3_score = len(mmf3.intersection(oleg_all)) / len(oleg_all)\n",
    "pws_score = len(pws.intersection(oleg_all)) / len(oleg_all)\n",
    "all_score = len(all.intersection(oleg_all)) / len(oleg_all)\n",
    "ours_score = len(ours_pred.intersection(oleg_all)) / len(oleg_all)\n",
    "\n",
    "print(f'mmf1: {mmf1_score:.2f}')\n",
    "print(f'mmf3: {mmf3_score:.2f}')\n",
    "print(f'pws: {pws_score:.2f}')\n",
    "print(f'all: {all_score:.2f}')\n",
    "print(f'ours: {ours_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmf1: 0.747\n",
      "mmf3: 0.740\n",
      "pws: 0.620\n",
      "all: 1.000\n",
      "ours: 0.813\n"
     ]
    }
   ],
   "source": [
    "mmf1_score = len(mmf1.intersection(oleg_test)) / len(oleg_test)\n",
    "mmf3_score = len(mmf3.intersection(oleg_test)) / len(oleg_test)\n",
    "pws_score = len(pws.intersection(oleg_test)) / len(oleg_test)\n",
    "all_score = len(all.intersection(oleg_test)) / len(oleg_test)\n",
    "ours_score = len(ours_pred.intersection(oleg_test)) / len(oleg_test)\n",
    "\n",
    "print(f'mmf1: {mmf1_score:.3f}')\n",
    "print(f'mmf3: {mmf3_score:.3f}')\n",
    "print(f'pws: {pws_score:.3f}')\n",
    "print(f'all: {all_score:.3f}')\n",
    "print(f'ours: {ours_score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ours_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-7da89a627e68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mours_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ours_test' is not defined"
     ]
    }
   ],
   "source": [
    "len(ours_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
